---
title: "Árbol de Decisión y Random Forest: La Calificación de los Partidos Políticos en México"
css: custom.css

execute:
  enabled: true
  kernel: python3
---

# Modelo de Árbol de Decisión: {.fade-in}

## Cargar las Libererías: {.fade-in}
```{python}
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import accuracy_score, f1_score
import seaborn as sns
import matplotlib.pyplot as plt
import category_encoders as ce
import numpy as np
import pandas as pd

from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.metrics import accuracy_score, f1_score
```

## Cargar los Datos:  {.fade-in} 
Se cargan los datos desde un archivo CSV utilizando la librería `pandas`.

```{python}
df = pd.read_csv('/home/barea/randomforest/{{cookiecutter.project_slug}}/data/Partido_2023.csv')
df.head(10)
```

## Imputar los Datos del Tibble por la Mediana: {.fade-in}
Se imputan los valores nulos en el DataFrame utilizando la mediana de cada columna.
```{python}
df = df.fillna(df.median())
```

## Explorarar si Existen Valores Nulos: {.fade-in}
Se verifica la existencia de valores nulos en el Tibble.
```{python}
df.isnull().sum()
```

## Separar de Variables Predictoras y Objetivo: {.fade-in}
Se separan las variables predictoras (X) de la variable objetivo (y).
```{python}
X = df.drop(['P11_1A_19'], axis=1)
y = df['P11_1A_19']
```

# Dividir de Datos en Conjuntos de Entrenamiento y Prueba: {.fade-in}
Se dividen los datos en conjuntos de entrenamiento y prueba.
```{python}
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)
```

## Conocer las Variables Predictoras y de Entrenamiento: {.fade-in}
```{python}
print(X_train.columns) 
print(X_test.columns)
``` 

## Codificar las Variables: {.fade-in}
Se codifican las variables categóricas utilizando `OrdinalEncoder`.
```{python}
encoder = ce.OrdinalEncoder(cols=[
'P11_1_19',
'P11_1A_12',
'P11_1A_17',
'P11_1A_18',
'P11_1A_22',
'P11_1A_23',
])

X_train_encoded = encoder.fit_transform(X_train)
X_test_encoded = encoder.transform(X_test)
```

## Asegurar que no Haya Valores NaN o inf en los Datos de Entrenamiento y Prueba: {.fade-in}
Se aseguran que no existan valores NaN o infinitos en los datos de entrenamiento y prueba.
```{python}
X_train = X_train.replace([np.inf, -np.inf], np.nan).dropna()
X_test = X_test.replace([np.inf, -np.inf], np.nan).dropna()
```

## Buscar los Hiperparámetros del Árbpl de Decisión: {.fade-in}
Se realiza una búsqueda de hiperparámetros para el modelo de Árbol de Decisión utilizando GridSearchCV.
```{python}

param_grid = {
    'max_depth': [2, 4, 6, 8, 10],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}
grid_search_tree = GridSearchCV(DecisionTreeClassifier(random_state=0), param_grid, cv=5)
grid_search_tree.fit(X_train, y_train)
best_tree = grid_search_tree.best_estimator_

```

## Predecir y Evaluar del Árbol de Decisión: {.fade-in}
Se predicen y evalúan los resultados del modelo de Árbol de Decisión.
```{python}
y_train_pred_tree = best_tree.predict(X_train)
y_test_pred_tree = best_tree.predict(X_test)

train_accuracy_tree = accuracy_score(y_train, y_train_pred_tree)
test_accuracy_tree = accuracy_score(y_test, y_test_pred_tree)
train_f1_tree = f1_score(y_train, y_train_pred_tree, average='micro')
test_f1_tree = f1_score(y_test, y_test_pred_tree, average='micro')

print('Accuracy en train (árbol de decisión):', train_accuracy_tree)
print('Accuracy en test (árbol de decisión):', test_accuracy_tree)
print("El f1 score en train (árbol de decisión): ", train_f1_tree)
print("El f1 score en test (árbol de decisión): ", test_f1_tree)
```

# Visualización de la importancia de las características en el Árbol de Decisión: {.fade-in}
Se visualiza la importancia de las características en el modelo de Árbol de Decisión.
```{python}
importances_tree = best_tree.feature_importances_
sns.barplot(x=X.columns, y=importances_tree, palette='bright', saturation=2.0, edgecolor='black', linewidth=2)
plt.title('Importancia de cada Feature en el Árbol de Decisión')
plt.show()
```

# Modelo de Ramdom Forest: {.fade-in}
```{python}	
import matplotlib.pyplot as plt
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score
```

## Dividir el Conjunto de Datos en Entrenamiento y Prueba: {.fade-in}
Se dividen los datos en conjuntos de entrenamiento y prueba.
```{python}
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
```

## Ajustar el Modelo de Random Forest: {.fade-in}
Se ajusta el modelo de Random Forest con los datos de entrenamiento.
```{python}
modelo_rf = RandomForestClassifier(n_estimators=100, random_state=42)
modelo_rf.fit(X_train, y_train)
```

# Predecir y Evaluar el  Modelo: {.fade-in}
Se predicen y evalúan los resultados del modelo de Random Forest.
```{python}
y_train_pred = modelo_rf.predict(X_train)
y_test_pred = modelo_rf.predict(X_test)
print("Accuracy en train:", accuracy_score(y_train, y_train_pred))
print("Accuracy en test:", accuracy_score(y_test, y_test_pred))
print("F1 Score en train:", f1_score(y_train, y_train_pred, average='macro'))
print("F1 Score en test:", f1_score(y_test, y_test_pred, average='macro'))
```

## Preparar Datos para Visualizar: {.fade-in}
```{python}
importances = modelo_rf.feature_importances_
feature_names = X_train.columns
```

## Visualizar la Importancia de las Características: {.fade-in}
Se visualiza la importancia de las características en el modelo de Random Forest.
```{python}
indices = np.argsort(importances)[::-1]
plt.figure(figsize=(15, 6))
plt.title("Importancia de cada Feature en el Random Forest")
plt.bar(range(X_train.shape[1]), importances[indices], align="center")
plt.xticks(range(X_train.shape[1]), feature_names[indices], rotation=90)
plt.xlim([-1, X_train.shape[1]])
plt.show()
```